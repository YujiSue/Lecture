{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TWMU_2020_s1_Lecture-02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YujiSue/Lecture/blob/master/TWMU_2020_s1_Lecture_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtBrbcKDKj2M",
        "colab_type": "text"
      },
      "source": [
        "# AIによる画像識別  \n",
        "## まずは実際にAIの能力を確かめてみます  \n",
        "1. 適当に画像をダウンロード  \n",
        "2. その画像が何の画像かAIに聞いてみる\n",
        "3. AIが予想確率をつけて答えてくれるので、結果を表示  \n",
        "  \n",
        "## この流れを一通り見ていきましょう\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yka4eQsnKm6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 画像をダウンロード\n",
        "\n",
        "#ネット上から画像をダウンロードするのに必要なPythonプログラムを読み込みます\n",
        "import requests\n",
        "\n",
        "#画像表示に必要なPythonプログラムを読み込みます\n",
        "from IPython.display import Image, display_jpeg, display_png, display_pdf\n",
        "\n",
        "#画像をダウンロードします\n",
        "# requests.get(画像のURL)を実行して、responseの中に結果を代入します\n",
        "画像のURL1 = 'https://d1f5hsy4d47upe.cloudfront.net/d1/d17d3c7acf2d4444eee24cdd47200d5f_t.jpeg'\n",
        "response = requests.get(画像のURL1)\n",
        "\n",
        "# 画像の名前を決めます\n",
        "画像名１ = 'dog.jpeg'\n",
        "\n",
        "#（空の）画像ファイルを用意します\n",
        "# open('好きなファイル名', 'wb')でファイルを作成し、そのファイルを imgfile_1 に代入します\n",
        "画像ファイル１ = open(画像名１, 'wb')\n",
        "\n",
        "# ダウンロードした画像をファイルに書き込みます\n",
        "画像ファイル１.write(response.content)\n",
        "\n",
        "#画像を表示します\n",
        "display_jpeg(Image(画像名１))\n",
        "\n",
        "# ※ダウンロードしたファイルがjpegでない(png)場合は、\n",
        "# display_png(Image('画像ファイル名'))\n",
        "# とします\n",
        "\n",
        "# 自分の好きな画像をダウンロードしたい場合は、\n",
        "# 上のコードを見ながら\n",
        "# 画像のURL２ = '好きな画像のアドレス'\n",
        "# response = requests.get('画像のURL２')\n",
        "# 画像名２ = '好きな名前.jpg'\n",
        "# 画像ファイル２ = open(image_name2, 'wb')\n",
        "# 画像ファイル２.write(response.content)\n",
        "# ...のようにしましょう\n",
        "\n",
        "# ※注意：画像のURLは必ず画像本体を示すアドレスでなくてはいけません。\n",
        "# 例えばTwitterなどで写真が見れる以下のようなアドレスは画像だけのアドレスではありません\n",
        "# https://twitter.com/SHARP_JP/status/717912259607994370/photo/1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA3IT5hhKqJQ",
        "colab_type": "text"
      },
      "source": [
        "- 世の中には、すでにディープラーニングを簡単に扱えるようにしたプログラム群が存在します。  \n",
        "- 有名どころは [Tensorflow](https://www.tensorflow.org/), [keras](https://keras.io/ja/),[chainer](https://chainer.org/)あたりです  \n",
        "- Tensorflowは、比較的早い時期にgoogleが発表したもので、他のプログラムの基盤に使われていたりします  \n",
        "- 今回はkerasを使います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2cA-ArKtAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.画像が何の画像かAIに聞いてみる\n",
        "\n",
        "# 必要なプログラム群を読み込んでいきます\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# すでに研究者が学習させた人工知能を読み込みます\n",
        "テストAI = ResNet50(weights='imagenet')\n",
        "\n",
        "# さきほどダウンロードした画像をあらためて読み込みます\n",
        "画像 = image.load_img(画像名１, target_size=(224, 224))\n",
        "\n",
        "# 画像データをAIが認識できる形に変換・前処理します\n",
        "変換画像 = image.img_to_array(画像)\n",
        "変換画像 = np.expand_dims(変換画像, axis=0)\n",
        "変換画像 = preprocess_input(変換画像)\n",
        "# AIに予測させて結果を取得します\n",
        "予測 = テストAI.predict(変換画像)\n",
        "結果 = decode_predictions(予測, top=3)[0]\n",
        "\n",
        "# 3.結果を表示\n",
        "display_jpeg(Image(image_name1))\n",
        "print('第１候補：', 結果[0][1], '(予想確率：', 結果[0][2]*100, '％）')\n",
        "print('第２候補：', 結果[1][1], '(予想確率：', 結果[1][2]*100, '％）')\n",
        "print('第３候補：', 結果[2][1], '(予想確率：', 結果[2][2]*100, '％）')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0goLUwOXKwyF",
        "colab_type": "text"
      },
      "source": [
        "イヌ科には詳しくないですが、間違いなくディンゴではない...  \n",
        "前回の「りんな」しかり、最新のAIといっても意外とこんなもんです。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhkXEog_LE2j",
        "colab_type": "text"
      },
      "source": [
        "# Pythonの画像処理\n",
        "## もう少し練習モード\n",
        "\n",
        "- 人間の視覚情報処理と同じように色や形状を抽出  \n",
        "- 抽出した要素を組み合わせて、特徴パターンを学習\n",
        "- 特徴パターンをもとに、物体検出\n",
        "  \n",
        "せっかくなので、この辺の流れをPythonで実行してみましょう。  \n",
        "今度は[OpenCV](https://opencv.org/)というプログラム群を使います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mYyJBP1LxFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 必要なファイルをダウンロード\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg/800px-Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg -O MonaLisa.jpg\n",
        "!wget http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/_static/opencv-logo-white.png -O OpenCV.png\n",
        "!wget https://lh3.googleusercontent.com/proxy/9aSy2jrj-61nTCeAGtqxNMRaq_LsCVbLd2D9MFAGw8VE9IYp64wvpJUYiEeu8mfi9JDvRmBMXJN2Mf_tx7o5I6NGrDa8TKBTArF4jg4EqIrcKx0EpxQJgnyM35iQoe2GTw -O Oden.png\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye.xml\n",
        "\n",
        "# OpenCVなどの導入\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import display, Image, clear_output\n",
        "\n",
        "# オブジェクト外（グローバル）に画像表示用関数を作る\n",
        "# 特定のオブジェクトに縛られない\n",
        "def showCVImage(mat):\n",
        "  decoded_bytes = cv2.imencode('.jpg', mat)[1].tobytes()\n",
        "  display(Image(data=decoded_bytes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i33qhDreak4I",
        "colab_type": "text"
      },
      "source": [
        "## 色の抽出\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bywSYK9alT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # 画像読み込み\n",
        "アイコン = cv2.imread('OpenCV.png')\n",
        "# 色の抽出\n",
        "print('元の画像')\n",
        "showCVImage(アイコン)\n",
        "print('\\n')\n",
        "#赤色抽出\n",
        "下限色 = np.array([0, 0, 200]) # 青, 緑, 赤の順で指定\n",
        "上限色 = np.array([50, 50, 255])\n",
        "赤抽出 = cv2.inRange(アイコン, 下限色, 上限色)\n",
        "print('赤だけ')\n",
        "showCVImage(赤抽出)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLVzyxRbcmEq",
        "colab_type": "text"
      },
      "source": [
        "## 形状の抽出\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aZyoeg2dZ87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 画像の読み込み\n",
        "おでん = cv2.imread('Oden.png')\n",
        "\n",
        "# 直線を検出\n",
        "おでんグレー = cv2.cvtColor(おでん,cv2.COLOR_BGR2GRAY)\n",
        "縁 = cv2.Canny(おでんグレー,50,150,apertureSize = 3)\n",
        "直線リスト = cv2.HoughLines(縁,1,np.pi/180,200)\n",
        "\n",
        "# 円形を検出\n",
        "円リスト = cv2.HoughCircles(おでんグレー,cv2.HOUGH_GRADIENT,1,100,param1=100,param2=100,minRadius=10)\n",
        "\n",
        "# 検出した個々の直線について\n",
        "for 線 in 直線リスト:\n",
        "  for rho,theta in 線:\n",
        "    # ベクトル計算と延長\n",
        "    a = np.cos(theta)\n",
        "    b = np.sin(theta)\n",
        "    x0 = a*rho\n",
        "    y0 = b*rho\n",
        "    x1 = int(x0 + 1000*(-b))\n",
        "    y1 = int(y0 + 1000*(a))\n",
        "    x2 = int(x0 - 1000*(-b))\n",
        "    y2 = int(y0 - 1000*(a))\n",
        "    # 検出した線を赤く引く\n",
        "    cv2.line(おでん,(x1,y1),(x2,y2),(0,0,255),2)\n",
        "\n",
        "# 検出した個々の円について\n",
        "for 円 in 円リスト[0]:\n",
        "    # 検出した円を緑で縁取り\n",
        "    cv2.circle(おでん,(円[0],円[1]),円[2],(0,255,0),2)\n",
        "\n",
        "# 表示\n",
        "おでん = cv2.resize(おでん, (256, 256))\n",
        "showCVImage(おでん)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CXMOdMU85Fp",
        "colab_type": "text"
      },
      "source": [
        "## 抽出した要素を組み合わせて、特徴パターンを学習\n",
        "## 特徴パターンをもとに、物体検出\n",
        "画像の中の特定の要素を抽出した結果、様々な物体ごとの特徴的なパターンを拾うことができます。  \n",
        "動物の脳には、顔に反応しやすい神経があります。  \n",
        "試しに、ヒトの顔や顔のパーツを検出してみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYwVMwEGpPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 特徴分類器の読み込み\n",
        "顔検出器 = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "目検出器 = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "\n",
        "# テスト用画像の読み込み\n",
        "モナリザさん = cv2.imread('MonaLisa.jpg')\n",
        "表示用画像 = cv2.imread('MonaLisa.jpg')\n",
        "# 計算を簡略化するためにモノクロ化\n",
        "モナリザさんグレー = cv2.cvtColor(モナリザさん, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 顔を検出\n",
        "顔 = 顔検出器.detectMultiScale(モナリザさんグレー)\n",
        "# 検出された全員の顔について\n",
        "for (x,y,w,h) in 顔:\n",
        "    # 検出した顔を青い四角で囲む\n",
        "    cv2.rectangle(表示用画像,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    # 顔画像（グレースケール）\n",
        "    顔グレー = モナリザさんグレー[y:y+h, x:x+w]\n",
        "    # 顔画像（カラースケール）\n",
        "    顔カラー = 表示用画像[y:y+h, x:x+w]\n",
        "    # 顔の中から目を検出\n",
        "    目位置 = []\n",
        "    目 = 目検出器.detectMultiScale(顔グレー, scaleFactor=1.07, minNeighbors=1)\n",
        "    # ある顔の中から検出された全ての目について\n",
        "    for (ex,ey,ew,eh) in 目:\n",
        "        目位置.append([ex,ey,ew,eh])\n",
        "        # 検出した目を緑の四角で囲む\n",
        "        cv2.rectangle(顔カラー,(ex,ey),(ex+ew,ey+eh),(0,255,0),1)\n",
        "\n",
        "表示用画像 = cv2.resize(表示用画像, (256, 256))\n",
        "showCVImage(表示用画像)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkys5FcLDFS",
        "colab_type": "text"
      },
      "source": [
        "# それでは本題にいきましょう\n",
        "ちょっと長くなったので[２つ目のファイル](https://colab.research.google.com/github/YujiSue/Lecture/blob/master/TWMU_2020_s1_Lecture_02_2.ipynb)にいきます"
      ]
    }
  ]
}